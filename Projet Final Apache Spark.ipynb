{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet Final Apache Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nom Etudiant :**  DIALLO\n",
    "\n",
    "**Prenom Etudiant:**  Ousmane\n",
    "\n",
    "**Classe :**  Master 1 Big Data Analytics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "Ce projet consiste à utiliser Apache Spark pour faire l'analyse et le traitement des données de **[San Francisco Fire Department Calls ](https://data.sfgov.org/Public-Safety/Fire-Department-Calls-for-Service/nuek-vuh3)** afin de fournir quelques KPI (*Key Performance Indicator*). Le **SF Fire Dataset** comprend les réponses aux appels de toutes les unités d'incendie. Chaque enregistrement comprend le numéro d'appel, le numéro d'incident, l'adresse, l'identifiant de l'unité, le type d'appel et la disposition. Tous les intervalles de temps pertinents sont également inclus. Étant donné que ce Dataset est basé sur les réponses et que la plupart des appels impliquent plusieurs unités, ainsi il existe plusieurs enregistrements pour chaque numéro d'appel. Les adresses sont associées à un numéro de bloc, à une intersection ou à une boîte d'appel, et non à une adresse spécifique.\n",
    "\n",
    "**Plus de details sur la description des données cliquer sur ce [lien](https://data.sfgov.org/Public-Safety/Fire-Department-Calls-for-Service/nuek-vuh3)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chargement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importation des packages Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://10.0.2.15:4040\n",
       "SparkContext available as 'sc' (version = 3.0.1, master = local[*], app id = local-1610275754814)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.sql.types._\n",
       "import org.apache.spark.sql.functions._\n",
       "import spark.implicits._\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.sql.types._ \n",
    "import org.apache.spark.sql.functions._ \n",
    "import spark.implicits._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons jeter un coup d'oeil sur la structure des données avant de définir un schéma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CallNumber,UnitID,IncidentNumber,CallType,CallDate,WatchDate,CallFinalDisposition,AvailableDtTm,Address,City,Zipcode,Battalion,StationArea,Box,OriginalPriority,Priority,FinalPriority,ALSUnit,CallTypeGroup,NumAlarms,UnitType,UnitSequenceInCallDispatch,FirePreventionDistrict,SupervisorDistrict,Neighborhood,Location,RowID,Delay\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!head -1 \"datasets/sf-fire/sf-fire-calls.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vu que la taille de ces données est énormes, inferer le schema pour un très grande volumes de données s'avère un peu couteux. Nous allons ainsi définir un schema pour le Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fireSchema: org.apache.spark.sql.types.StructType = StructType(StructField(CallNumber,IntegerType,true), StructField(UnitID,StringType,true), StructField(IncidentNumber,IntegerType,true), StructField(CallType,StringType,true), StructField(CallDate,StringType,true), StructField(WatchDate,StringType,true), StructField(CallFinalDisposition,StringType,true), StructField(AvailableDtTm,StringType,true), StructField(Address,StringType,true), StructField(City,StringType,true), StructField(Zipcode,IntegerType,true), StructField(Battalion,StringType,true), StructField(StationArea,StringType,true), StructField(Box,StringType,true), StructField(OriginalPriority,StringType,true), StructField(Priority,StringType,true), StructField(FinalPriority,IntegerType,true), StructField(ALSUnit,BooleanType,true)...\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val fireSchema = StructType(Array(\n",
    "  StructField(\"CallNumber\", IntegerType, true),\n",
    "  StructField(\"UnitID\", StringType, true),\n",
    "  StructField(\"IncidentNumber\", IntegerType, true),\n",
    "  StructField(\"CallType\", StringType, true),                  \n",
    "  StructField(\"CallDate\", StringType, true),      \n",
    "  StructField(\"WatchDate\", StringType, true),\n",
    "  StructField(\"CallFinalDisposition\", StringType, true),\n",
    "  StructField(\"AvailableDtTm\", StringType, true),\n",
    "  StructField(\"Address\", StringType, true),       \n",
    "  StructField(\"City\", StringType, true),       \n",
    "  StructField(\"Zipcode\", IntegerType, true),       \n",
    "  StructField(\"Battalion\", StringType, true),                 \n",
    "  StructField(\"StationArea\", StringType, true),       \n",
    "  StructField(\"Box\", StringType, true),       \n",
    "  StructField(\"OriginalPriority\", StringType, true),       \n",
    "  StructField(\"Priority\", StringType, true),       \n",
    "  StructField(\"FinalPriority\", IntegerType, true),       \n",
    "  StructField(\"ALSUnit\", BooleanType, true),       \n",
    "  StructField(\"CallTypeGroup\", StringType, true),\n",
    "  StructField(\"NumAlarms\", IntegerType, true),\n",
    "  StructField(\"UnitType\", StringType, true),\n",
    "  StructField(\"UnitSequenceInCallDispatch\", IntegerType, true),\n",
    "  StructField(\"FirePreventionDistrict\", StringType, true),\n",
    "  StructField(\"SupervisorDistrict\", StringType, true),\n",
    "  StructField(\"Neighborhood\", StringType, true),\n",
    "  StructField(\"Location\", StringType, true),\n",
    "  StructField(\"RowID\", StringType, true),\n",
    "  StructField(\"Delay\", FloatType, true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sfFireFile: String = datasets/sf-fire/sf-fire-calls.csv\n",
       "fireDF: org.apache.spark.sql.DataFrame = [CallNumber: int, UnitID: string ... 26 more fields]\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val sfFireFile = \"datasets/sf-fire/sf-fire-calls.csv\"\n",
    "val fireDF = spark\n",
    "  .read\n",
    "  .schema(fireSchema)\n",
    "  .option(\"header\", \"true\")\n",
    "  .csv(sfFireFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons mettre en cache le Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res0: fireDF.type = [CallNumber: int, UnitID: string ... 26 more fields]\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fireDF.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "res1: Long = 175296\n"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fireDF.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CallNumber: integer (nullable = true)\n",
      " |-- UnitID: string (nullable = true)\n",
      " |-- IncidentNumber: integer (nullable = true)\n",
      " |-- CallType: string (nullable = true)\n",
      " |-- CallDate: string (nullable = true)\n",
      " |-- WatchDate: string (nullable = true)\n",
      " |-- CallFinalDisposition: string (nullable = true)\n",
      " |-- AvailableDtTm: string (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Zipcode: integer (nullable = true)\n",
      " |-- Battalion: string (nullable = true)\n",
      " |-- StationArea: string (nullable = true)\n",
      " |-- Box: string (nullable = true)\n",
      " |-- OriginalPriority: string (nullable = true)\n",
      " |-- Priority: string (nullable = true)\n",
      " |-- FinalPriority: integer (nullable = true)\n",
      " |-- ALSUnit: boolean (nullable = true)\n",
      " |-- CallTypeGroup: string (nullable = true)\n",
      " |-- NumAlarms: integer (nullable = true)\n",
      " |-- UnitType: string (nullable = true)\n",
      " |-- UnitSequenceInCallDispatch: integer (nullable = true)\n",
      " |-- FirePreventionDistrict: string (nullable = true)\n",
      " |-- SupervisorDistrict: string (nullable = true)\n",
      " |-- Neighborhood: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- RowID: string (nullable = true)\n",
      " |-- Delay: float (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fireDF.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+--------------+----------------+----------+----------+--------------------+--------------------+--------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+--------------------+--------------------+-------------+---------+\n",
      "|CallNumber|UnitID|IncidentNumber|        CallType|  CallDate| WatchDate|CallFinalDisposition|       AvailableDtTm|             Address|City|Zipcode|Battalion|StationArea| Box|OriginalPriority|Priority|FinalPriority|ALSUnit|CallTypeGroup|NumAlarms|UnitType|UnitSequenceInCallDispatch|FirePreventionDistrict|SupervisorDistrict|        Neighborhood|            Location|        RowID|    Delay|\n",
      "+----------+------+--------------+----------------+----------+----------+--------------------+--------------------+--------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+--------------------+--------------------+-------------+---------+\n",
      "|  20110016|   T13|       2003235|  Structure Fire|01/11/2002|01/10/2002|               Other|01/11/2002 01:51:...|2000 Block of CAL...|  SF|  94109|      B04|         38|3362|               3|       3|            3|  false|         null|        1|   TRUCK|                         2|                     4|                 5|     Pacific Heights|(37.7895840679362...|020110016-T13|     2.95|\n",
      "|  20110022|   M17|       2003241|Medical Incident|01/11/2002|01/10/2002|               Other|01/11/2002 03:01:...|0 Block of SILVER...|  SF|  94124|      B10|         42|6495|               3|       3|            3|   true|         null|        1|   MEDIC|                         1|                    10|                10|Bayview Hunters P...|(37.7337623673897...|020110022-M17|      4.7|\n",
      "|  20110023|   M41|       2003242|Medical Incident|01/11/2002|01/10/2002|               Other|01/11/2002 02:39:...|MARKET ST/MCALLIS...|  SF|  94102|      B03|         01|1455|               3|       3|            3|   true|         null|        1|   MEDIC|                         2|                     3|                 6|          Tenderloin|(37.7811772186856...|020110023-M41|2.4333334|\n",
      "|  20110032|   E11|       2003250|    Vehicle Fire|01/11/2002|01/10/2002|               Other|01/11/2002 04:16:...|APPLETON AV/MISSI...|  SF|  94110|      B06|         32|5626|               3|       3|            3|  false|         null|        1|  ENGINE|                         1|                     6|                 9|      Bernal Heights|(37.7388432849018...|020110032-E11|      1.5|\n",
      "|  20110043|   B04|       2003259|          Alarms|01/11/2002|01/10/2002|               Other|01/11/2002 06:01:...|1400 Block of SUT...|  SF|  94109|      B04|         03|3223|               3|       3|            3|  false|         null|        1|   CHIEF|                         2|                     4|                 2|    Western Addition|(37.7872890372638...|020110043-B04|3.4833333|\n",
      "+----------+------+--------------+----------------+----------+----------+--------------------+--------------------+--------------------+----+-------+---------+-----------+----+----------------+--------+-------------+-------+-------------+---------+--------+--------------------------+----------------------+------------------+--------------------+--------------------+-------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fireDF.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtrage des d'appels de type \"Medical Incident\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------------------+--------------+\n",
      "|IncidentNumber|AvailableDtTm         |CallType      |\n",
      "+--------------+----------------------+--------------+\n",
      "|2003235       |01/11/2002 01:51:44 AM|Structure Fire|\n",
      "|2003250       |01/11/2002 04:16:46 AM|Vehicle Fire  |\n",
      "|2003259       |01/11/2002 06:01:58 AM|Alarms        |\n",
      "|2003279       |01/11/2002 08:03:26 AM|Structure Fire|\n",
      "|2003301       |01/11/2002 09:46:44 AM|Alarms        |\n",
      "+--------------+----------------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "fewFireDF: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [IncidentNumber: int, AvailableDtTm: string ... 1 more field]\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val fewFireDF = fireDF\n",
    "  .select(\"IncidentNumber\", \"AvailableDtTm\", \"CallType\") \n",
    "  .where($\"CallType\" =!= \"Medical Incident\")\n",
    "\n",
    "fewFireDF.show(5, false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "**Combien de types d'appels distincts ont été passés ?**  \n",
    "Pour être sûr, il ne faut pas compter les valeurs «nulles» dans la colonne."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cas de figure pour ne pas prendre en compte les valeurs null, on a utilisé la fonction **isNotNull**.\n",
    "Ainsi on peut selectionner les lignes de la colonne \"CallType\" sans valeurs nulles et utiliser les fonctions **distinct** et **count** pour compter    les valeurs différentes et les affecter à la variable **callTypeCount**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "callTypeCount: Long = 30\n",
       "res6: Long = 30\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Reponse 1\n",
    "\n",
    "val callTypeCount = fireDF\n",
    "    .select(\"CallType\")\n",
    "    .filter(col(\"CallType\").isNotNull)\n",
    "    .distinct()\n",
    "    .count()\n",
    "callTypeCount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Quels types d'appels différents ont été passés au service d'incendie?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cette cellule on fait comme à la précédente mais en enlèvant la fonction **count()** pour trouver seulement les valeurs de \"CallType\" difféntes\n",
    "Ensuite on affiche le résultat avec la fonction **show** qui quant lui applique l'argument **false** affiche correctement les textes sans les abrèger. L'argument *30* est justifié par le fait qu'on a trouvé 30 types d'appels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------+\n",
      "|CallType                                    |\n",
      "+--------------------------------------------+\n",
      "|Elevator / Escalator Rescue                 |\n",
      "|Marine Fire                                 |\n",
      "|Aircraft Emergency                          |\n",
      "|Confined Space / Structure Collapse         |\n",
      "|Administrative                              |\n",
      "|Alarms                                      |\n",
      "|Odor (Strange / Unknown)                    |\n",
      "|Citizen Assist / Service Call               |\n",
      "|HazMat                                      |\n",
      "|Watercraft in Distress                      |\n",
      "|Explosion                                   |\n",
      "|Oil Spill                                   |\n",
      "|Vehicle Fire                                |\n",
      "|Suspicious Package                          |\n",
      "|Extrication / Entrapped (Machinery, Vehicle)|\n",
      "|Other                                       |\n",
      "|Outside Fire                                |\n",
      "|Traffic Collision                           |\n",
      "|Assist Police                               |\n",
      "|Gas Leak (Natural and LP Gases)             |\n",
      "|Water Rescue                                |\n",
      "|Electrical Hazard                           |\n",
      "|High Angle Rescue                           |\n",
      "|Structure Fire                              |\n",
      "|Industrial Accidents                        |\n",
      "|Medical Incident                            |\n",
      "|Mutual Aid / Assist Outside Agency          |\n",
      "|Fuel Spill                                  |\n",
      "|Smoke Investigation (Outside)               |\n",
      "|Train / Rail Incident                       |\n",
      "+--------------------------------------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "callType: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [CallType: string]\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Reponse 2\n",
    "\n",
    "val callType = fireDF\n",
    "    .select(\"CallType\")\n",
    "    .filter(col(\"CallType\").isNotNull)\n",
    "    .distinct()\n",
    "\n",
    "callType.show(30, false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "**Trouver toutes les réponses ou les délais sont supérieurs à 5 minutes?**\n",
    "\n",
    "*Indication\n",
    "1. Renommer la colonne Delay -> ReponseDelayedinMins\n",
    "2. Retourner un nouveau DataFrame\n",
    "3. Afficher tous les appels où le temps de réponse à un site d'incendie a eu lieu après un retard de plus de 5 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après avoir eu la nouvelle base de données **newFireDF** avec le renommage de la colonne \"Delay\" en \"ResponseDelayedinMins\" on peut ainsi:<br>\n",
    " * créer une variable **responseDelayAboveFive** qui va recevoir les données retournées\n",
    " * Selectionner les colonnes (\"CallNumber\", \"IncidentNumber\", \"ResponseDelayedinMins\")\n",
    " * Appliquer un filtre et choisir les cas ou le delais de réponse est supérieur à 5 minutes avec le clause **where** <br>\n",
    "Par soucis de présentation on affiche les 20 premières lignes du résultats avec la fonction **show** on peut tout de même afficher toutes les lignes avec la fonction **collect** : *responseDelayAboveFive.collect().foreach(println)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------+---------------------+\n",
      "|CallNumber|IncidentNumber|ResponseDelayedinMins|\n",
      "+----------+--------------+---------------------+\n",
      "|20110315  |2003409       |5.35                 |\n",
      "|20120147  |2003642       |6.25                 |\n",
      "|20130013  |2003818       |5.2                  |\n",
      "|20140067  |2004152       |5.6                  |\n",
      "|20140177  |2004216       |7.25                 |\n",
      "|20150056  |2004408       |11.916667            |\n",
      "|20150254  |2004521       |5.116667             |\n",
      "|20150265  |2004528       |8.633333             |\n",
      "|20150265  |2004528       |95.28333             |\n",
      "|20150380  |2004610       |5.45                 |\n",
      "|20150414  |2004641       |7.6                  |\n",
      "|20160059  |2004721       |6.133333             |\n",
      "|20160064  |2004724       |5.1833334            |\n",
      "|20170118  |2005038       |6.9166665            |\n",
      "|20170342  |2005173       |5.2                  |\n",
      "|20180129  |2005321       |6.35                 |\n",
      "|20180191  |2005353       |7.983333             |\n",
      "|20180382  |2005480       |13.55                |\n",
      "|20190062  |2005599       |5.15                 |\n",
      "|20190097  |2005623       |13.583333            |\n",
      "+----------+--------------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "newFireDF: org.apache.spark.sql.DataFrame = [CallNumber: int, UnitID: string ... 26 more fields]\n",
       "responseDelayAboveFive: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [CallNumber: int, IncidentNumber: int ... 1 more field]\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Reponse 3\n",
    "val newFireDF = fireDF.withColumnRenamed(\"Delay\", \"ResponseDelayedinMins\")\n",
    "\n",
    "val responseDelayAboveFive = newFireDF\n",
    "    .select(\"CallNumber\", \"IncidentNumber\", \"ResponseDelayedinMins\")\n",
    "    .where($\"ResponseDelayedinMins\" > 5)\n",
    "\n",
    "responseDelayAboveFive.show(false)\n",
    "//responseDelayAboveFive.collect().foreach(println)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformations des dates\n",
    "Maintenant nous allons d'abord:\n",
    "1. Transformer les dates de type String en Spark Timestamp afin que nous puissions effectuer des requêtes basées sur la date plus tard\n",
    "2. Retourner le Dataframe transformée\n",
    "3. Mettre en cache le nouveau DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fireTSDF: org.apache.spark.sql.DataFrame = [CallNumber: int, UnitID: string ... 26 more fields]\n",
       "res9: fireTSDF.type = [CallNumber: int, UnitID: string ... 26 more fields]\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val fireTSDF = newFireDF\n",
    "  .withColumn(\"IncidentDate\", to_timestamp(col(\"CallDate\"), \"MM/dd/yyyy\")).drop(\"CallDate\") \n",
    "  .withColumn(\"OnWatchDate\", to_timestamp(col(\"WatchDate\"), \"MM/dd/yyyy\")).drop(\"WatchDate\") \n",
    "  .withColumn(\"AvailableDtTS\", to_timestamp(col(\"AvailableDtTm\"), \"MM/dd/yyyy hh:mm:ss a\")).drop(\"AvailableDtTm\")\n",
    "\n",
    "fireTSDF.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "**Quels sont les types d'appels les plus courants?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour trouver les types d'appels les plus courants on fait une projection sur la colonne \"CallType\" et ensuite on lui applique les conditions suivantes:\n",
    " * groupBy(\"CallType\") pour aggrèger les type d'appel\n",
    " * count() pour compter le nombre de type d'appel\n",
    " * orderBy(desc(\"count\")) pour ordonner le résultat suivant le plus grand nombre associé au type d'appel et de manière décroissante\n",
    " * limit(3) pour limiter le résultat au top 3 de la liste car leurs nombres est largement plus grands que les autres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------+\n",
      "|CallType        |count |\n",
      "+----------------+------+\n",
      "|Medical Incident|113794|\n",
      "|Structure Fire  |23319 |\n",
      "|Alarms          |19406 |\n",
      "+----------------+------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "mostCommonCalls: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [CallType: string, count: bigint]\n"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Reponse 4\n",
    "\n",
    "val mostCommonCalls = fireTSDF\n",
    "    .select(\"CallType\")\n",
    "    .groupBy(\"CallType\")\n",
    "    .count()\n",
    "    .orderBy(desc(\"count\"))\n",
    "    .limit(3)\n",
    "\n",
    "mostCommonCalls.show(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5-a\n",
    "**Quels sont boites postaux rencontrés dans les appels les plus courants?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour touver les boites postales rencontrées dans les appels les plus courants, on selectionne toutes les boites postales ensuite on fait un filtre suivant les types d'appels les plus courants qui sont \"Medical Incident\", \"Structure Fire\" et \"Alarms\"\n",
    "Aussi par soucis de présentation on affiche que 20 lignes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|Zipcode|\n",
      "+-------+\n",
      "|94109  |\n",
      "|94115  |\n",
      "|94112  |\n",
      "|94127  |\n",
      "|94108  |\n",
      "|94121  |\n",
      "|94105  |\n",
      "|94131  |\n",
      "|94134  |\n",
      "|94124  |\n",
      "|94102  |\n",
      "|94114  |\n",
      "|94111  |\n",
      "|94103  |\n",
      "|94117  |\n",
      "|94122  |\n",
      "|94110  |\n",
      "|94132  |\n",
      "|94104  |\n",
      "|94133  |\n",
      "+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "mostCommonZip: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [Zipcode: int]\n"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Reponse 5-a\n",
    "\n",
    "val mostCommonZip = fireTSDF\n",
    "    .select(\"Zipcode\")\n",
    "    .distinct()\n",
    "    .where($\"CallType\" === \"Medical Incident\" || \n",
    "           $\"CallType\" === \"Structure Fire\" || \n",
    "           $\"CallType\" === \"Alarms\")\n",
    "\n",
    "mostCommonZip.show(false)\n",
    "//mostCommonZip.collect().foreach(println)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5-a\n",
    "**Quels sont les quartiers de San Francisco dont les codes postaux sont 94102 et 94103?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour répondre à cette question on fait comme suit:\n",
    "   * selection des quartiers , des villes et des boites postales(\"Neighborhood\", \"Zipcode\", \"City\")\n",
    "   * chosir ceux de la ville de San Francisco et des boites postales \"94102\" ou \"94103\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-------+-------------+\n",
      "|Neighborhood    |Zipcode|City         |\n",
      "+----------------+-------+-------------+\n",
      "|South of Market |94103  |San Francisco|\n",
      "|Mission         |94103  |San Francisco|\n",
      "|South of Market |94103  |San Francisco|\n",
      "|South of Market |94103  |San Francisco|\n",
      "|South of Market |94103  |San Francisco|\n",
      "|Tenderloin      |94102  |San Francisco|\n",
      "|South of Market |94103  |San Francisco|\n",
      "|South of Market |94103  |San Francisco|\n",
      "|South of Market |94103  |San Francisco|\n",
      "|South of Market |94103  |San Francisco|\n",
      "|Mission         |94103  |San Francisco|\n",
      "|Mission         |94103  |San Francisco|\n",
      "|Tenderloin      |94102  |San Francisco|\n",
      "|Tenderloin      |94102  |San Francisco|\n",
      "|South of Market |94103  |San Francisco|\n",
      "|Tenderloin      |94102  |San Francisco|\n",
      "|Tenderloin      |94102  |San Francisco|\n",
      "|South of Market |94103  |San Francisco|\n",
      "|Western Addition|94102  |San Francisco|\n",
      "|South of Market |94103  |San Francisco|\n",
      "+----------------+-------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "sfNbh: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [Neighborhood: string, Zipcode: int ... 1 more field]\n"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Reponse 5-b\n",
    "\n",
    "val sfNbh = fireTSDF\n",
    "    .select(\"Neighborhood\", \"Zipcode\", \"City\")\n",
    "    .where($\"City\" === \"San Francisco\" && \n",
    "           ($\"Zipcode\" === 94102 || $\"Zipcode\" === 94103))\n",
    "\n",
    "sfNbh.show(false)\n",
    "//sfNbh.collect().foreach(println)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "**Determiner le nombre total d'appels, ainsi que la moyenne, le minimum et le maximum du temps de réponse des appels?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour afficher les statistiques sur une colonne d'un dataframe on l'applique la fonction describe suivi d'un show\n",
    "\n",
    "Mais pour être plus précis ici on va le faire en choisissant les estimateurs que l'on nous demande d'afficher.\n",
    " * count: nous permet d'avoir le nombre total\n",
    " * mean: nous permet d'avoir la moyenne\n",
    " * min et max: nous donne le minimum et le maximum\n",
    " * round: nous permet d'arrondir le résultat et d'avoir un résultat plus commode à la lecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+----------+----------+----------+\n",
      "|Nombes total d'appels|La Moyenne|Le Minimum|Le Maximum|\n",
      "+---------------------+----------+----------+----------+\n",
      "|175296               |3.892     |0.017     |1844.55   |\n",
      "+---------------------+----------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "//Reponse 6\n",
    "fireTSDF.select(\n",
    "                count(\"ResponseDelayedinMins\").as(\"Nombes total d'appels\"), \n",
    "                round(mean(\"ResponseDelayedinMins\"), 3).as(\"La Moyenne\"),\n",
    "                round(min(\"ResponseDelayedinMins\"), 3).as(\"Le Minimum\"),\n",
    "                max(\"ResponseDelayedinMins\").as(\"Le Maximum\"))\n",
    "        .show(false)\n",
    "\n",
    "//fireTSDF.describe(\"ResponseDelayedinMins\").show(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7-a\n",
    "**Combien d'années distinctes trouve t-on dans ce Dataset?**  \n",
    "Dans ce dataset nous avons des données comprises entre 2000-2018. Vous pouvez utilisez la fonction Spark `year()` pour les dates en Timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour connaitre le nombre d'années que l'on trouve dans le dataset on choisit de se projeter sur la colonne \"IncidentDate\" car cette colonne marque l'activité du service puisque les appels déclenchent un enregistrement.\n",
    "Ensuite on compte le nombre d'années différentes que l'on extrait des dates avec la fontion de __year()__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nbOfYears: Long = 19\n",
       "res47: Long = 19\n"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Reponse 7-a\n",
    "\n",
    "val nbOfYears = fireTSDF\n",
    "    .select(year(col(\"IncidentDate\")))\n",
    "    .distinct()\n",
    "    .count()\n",
    "\n",
    "nbOfYears"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7-b\n",
    "**Quelle semaine de l'année 2018 a eu le plus d'appels d'incendie?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour trouver la semaine de l'année 2018 qui a eu le plus d'apels d'incendie on procède comme suit:\n",
    " * On cible l'année de l'incident qui est 2018\n",
    " * On cible les appels dont le type ou le nom contient le mot \"fire(feu ou incendie)\" qui est le mot clé de la recherche \n",
    " * On applique la fonction **lower** pour transformer la valeur de la colonne en miniscule car le mot clé est en miniscule\n",
    " * On se projette sur les semaines correspondant à ces appels, ensuite on les ordonnes par fréquence et on choisit le plus fréquent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|Fire Week|count|\n",
      "+---------+-----+\n",
      "|        1|   37|\n",
      "+---------+-----+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "hottestWeek: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [Fire Week: int, count: bigint]\n"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Reponse 7-b\n",
    "\n",
    "val hottestWeek = fireTSDF\n",
    "    .where(year(col(\"IncidentDate\")) === 2018)\n",
    "    .filter(lower(col(\"CallType\")).like(\"%fire%\"))\n",
    "    .select(weekofyear(col(\"IncidentDate\")).as(\"Fire Week\"))\n",
    "    .groupBy(\"Fire Week\")\n",
    "    .count()\n",
    "    .orderBy(desc(\"count\"))\n",
    "    .limit(1)\n",
    "   \n",
    "hottestWeek.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "**Quels sont les quartiers de San Francisco qui ont connu le pire temps de réponse en 2018?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour répondre à cette question nous allons:\n",
    " * d'abord cibler la ville de San Francisco et l'année 2018\n",
    " * ensuite, on fait une projection sur les colonnes \"Neighborhood\", \"ResponseDelayedinMins\"\n",
    " * enfin on fait une aggrégation suivant les quartiers et la moyenne des temps de réponse de chacun que l'on ordonne de manière décroissante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+------------------+\n",
      "|Neighborhood         |Average Delay     |\n",
      "+---------------------+------------------+\n",
      "|Treasure Island      |11.320833250880241|\n",
      "|Presidio             |6.248148073752721 |\n",
      "|Chinatown            |6.158818309742307 |\n",
      "|McLaren Park         |4.74404764175415  |\n",
      "|Bayview Hunters Point|4.629759605458373 |\n",
      "+---------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "worserDelay: org.apache.spark.sql.Dataset[org.apache.spark.sql.Row] = [Neighborhood: string, Average Delay: double]\n"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "//Reponse 8\n",
    "\n",
    "val worserDelay = fireTSDF\n",
    "    .where($\"City\" === \"San Francisco\")\n",
    "    .where(year(col(\"IncidentDate\")) === 2018)\n",
    "    .select(\"Neighborhood\", \"ResponseDelayedinMins\")\n",
    "    .groupBy(\"Neighborhood\")\n",
    "    .agg(avg(\"ResponseDelayedinMins\").as(\"Average Delay\"))\n",
    "    .orderBy(desc(\"Average Delay\"))\n",
    "    \n",
    "worserDelay.show(5, false) //on a choisi d'afficher le top 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9\n",
    "\n",
    "**Comment stocker les données du Dataframe sous format de fichiers Parquet?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "//Reponse 9\n",
    "\n",
    "fireTSDF.\n",
    "    write.\n",
    "    mode(\"overwrite\").\n",
    "    option(\"compression\", \"none\").\n",
    "    parquet(\"datasets/project/fireTSDF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 10\n",
    "**Comment relire les données stockée en format Parquet?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CallNumber: integer (nullable = true)\n",
      " |-- UnitID: string (nullable = true)\n",
      " |-- IncidentNumber: integer (nullable = true)\n",
      " |-- CallType: string (nullable = true)\n",
      " |-- CallFinalDisposition: string (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Zipcode: integer (nullable = true)\n",
      " |-- Battalion: string (nullable = true)\n",
      " |-- StationArea: string (nullable = true)\n",
      " |-- Box: string (nullable = true)\n",
      " |-- OriginalPriority: string (nullable = true)\n",
      " |-- Priority: string (nullable = true)\n",
      " |-- FinalPriority: integer (nullable = true)\n",
      " |-- ALSUnit: boolean (nullable = true)\n",
      " |-- CallTypeGroup: string (nullable = true)\n",
      " |-- NumAlarms: integer (nullable = true)\n",
      " |-- UnitType: string (nullable = true)\n",
      " |-- UnitSequenceInCallDispatch: integer (nullable = true)\n",
      " |-- FirePreventionDistrict: string (nullable = true)\n",
      " |-- SupervisorDistrict: string (nullable = true)\n",
      " |-- Neighborhood: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- RowID: string (nullable = true)\n",
      " |-- ResponseDelayedinMins: float (nullable = true)\n",
      " |-- IncidentDate: timestamp (nullable = true)\n",
      " |-- OnWatchDate: timestamp (nullable = true)\n",
      " |-- AvailableDtTS: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "//Reponse 10\n",
    "\n",
    "spark.read.parquet(\"datasets/project/fireTSDF\").printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- CallNumber: integer (nullable = true)\n",
      " |-- UnitID: string (nullable = true)\n",
      " |-- IncidentNumber: integer (nullable = true)\n",
      " |-- CallType: string (nullable = true)\n",
      " |-- CallFinalDisposition: string (nullable = true)\n",
      " |-- Address: string (nullable = true)\n",
      " |-- City: string (nullable = true)\n",
      " |-- Zipcode: integer (nullable = true)\n",
      " |-- Battalion: string (nullable = true)\n",
      " |-- StationArea: string (nullable = true)\n",
      " |-- Box: string (nullable = true)\n",
      " |-- OriginalPriority: string (nullable = true)\n",
      " |-- Priority: string (nullable = true)\n",
      " |-- FinalPriority: integer (nullable = true)\n",
      " |-- ALSUnit: boolean (nullable = true)\n",
      " |-- CallTypeGroup: string (nullable = true)\n",
      " |-- NumAlarms: integer (nullable = true)\n",
      " |-- UnitType: string (nullable = true)\n",
      " |-- UnitSequenceInCallDispatch: integer (nullable = true)\n",
      " |-- FirePreventionDistrict: string (nullable = true)\n",
      " |-- SupervisorDistrict: string (nullable = true)\n",
      " |-- Neighborhood: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- RowID: string (nullable = true)\n",
      " |-- ResponseDelayedinMins: float (nullable = true)\n",
      " |-- IncidentDate: timestamp (nullable = true)\n",
      " |-- OnWatchDate: timestamp (nullable = true)\n",
      " |-- AvailableDtTS: timestamp (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "//Reponse 10\n",
    "spark.read.parquet(\"datasets/project/fireTSDF\").printSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
